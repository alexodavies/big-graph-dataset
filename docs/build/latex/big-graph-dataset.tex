%% Generated by Sphinx.
\def\sphinxdocclass{article}
\documentclass[letterpaper,10pt,english]{sphinxhowto}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{booktabs}{sphinx}
\PassOptionsToPackage{colorrows}{sphinx}

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

\usepackage{nbsphinx}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}
\setcounter{tocdepth}{2}


    \usepackage{fontspec}
    

\title{Big Graph Dataset Documentation}
\date{Jun 06, 2024}
\release{0.01}
\author{Alex O. Davies}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxAtStartPar
This is a collaboration project to build a large, multi\sphinxhyphen{}domain set of graph datasets.
Each dataset comprises many small graphs.

\sphinxAtStartPar
The aim of this project is to provide a large set of graph datasets for use in machine learning research.
Currently graph datasets are distributed in individual repositories, increasing workload as researchers have to search for relevant resources.
Once these datasets are found, there is additional labour in formatting the data for use in deep learning.
\begin{description}
\sphinxlineitem{We aim to provide datasets that are:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Composed of many small graphs

\item {} 
\sphinxAtStartPar
Diverse in domain

\item {} 
\sphinxAtStartPar
Diverse in tasks

\item {} 
\sphinxAtStartPar
Well\sphinxhyphen{}documented

\item {} 
\sphinxAtStartPar
Formatted uniformly across datasets for Pytorch Geometric

\end{itemize}

\end{description}


\section{What we’re looking for}
\label{\detokenize{index:what-we-re-looking-for}}
\sphinxAtStartPar
In short: anything! The idea behind this being a collaboration is that we cast a wide net over different domains and tasks.

\sphinxAtStartPar
There are a few rules for this first phase (see below) but the quick brief is that we’re looking for datasets of small static graphs with well\sphinxhyphen{}defined tasks.
That just means that the structure of the graphs don’t vary over time.

\sphinxAtStartPar
If your data is a bit more funky, for example multi\sphinxhyphen{}graphs or time\sphinxhyphen{}series on graphs, please get in touch and we can discuss how to include it.

\sphinxAtStartPar
In the examples I’ve provided datasets are mostly sampled from one large graph \sphinxhyphen{} this is not compulsory.


\section{Contributing}
\label{\detokenize{index:contributing}}
\sphinxAtStartPar
The source can be found in the \sphinxtitleref{Github repository <https://github.com/neutralpronoun/big\sphinxhyphen{}graph\sphinxhyphen{}dataset>}.
\begin{description}
\sphinxlineitem{The basics:}\begin{itemize}
\item {} 
\sphinxAtStartPar
Create your own git branch

\item {} 
\sphinxAtStartPar
Copy the \sphinxtitleref{datasets/example\_dataset.py}

\item {} 
\sphinxAtStartPar
Have a look through

\item {} 
\sphinxAtStartPar
Re\sphinxhyphen{}tool it for your own dataset

\end{itemize}

\end{description}

\sphinxAtStartPar
I’ve provided code for sub\sphinxhyphen{}sampling graphs and producing statistics.
\begin{description}
\sphinxlineitem{A few rules, demonstrated in \sphinxtitleref{datasets/example\_dataset.py}:}\begin{itemize}
\item {} 
\sphinxAtStartPar
The datasets need at least a train/val/test split

\item {} 
\sphinxAtStartPar
Datasets should be many small (less than 400 node) graphs

\item {} 
\sphinxAtStartPar
Ideally the number of graphs in each dataset should be controllable

\item {} 
\sphinxAtStartPar
Data should be downloaded in\sphinxhyphen{}code to keep the repo small. If this isn’t possible let me know.

\item {} 
\sphinxAtStartPar
Please cite your sources for data in documentation \sphinxhyphen{} see the existing datasets for example documentation

\item {} 
\sphinxAtStartPar
Where possible start from existing datasets that have been used in\sphinxhyphen{}literature, or if using generators, use generators that are well\sphinxhyphen{}understood (for example Erdos\sphinxhyphen{}Renyi graphs)

\end{itemize}

\end{description}

\sphinxAtStartPar
Please document your dataset files with your name and contact information at the top, I’ll check code and merge your branches all at once at the end of the project.


\section{Getting Started}
\label{\detokenize{index:getting-started}}
\sphinxAtStartPar
Check out the Reddit dataset example notebook for a quick start guide, then have a look at the source code for the datasets.

\sphinxAtStartPar
My environment is under \sphinxtitleref{docs/requirements.txt}, use \sphinxtitleref{pip install \sphinxhyphen{}r requirements. txt} within a virtual (Conda etc.) environment to get everything installed.

\sphinxstepscope


\subsection{Reddit Example Dataset}
\label{\detokenize{reddit-dataset-example:Reddit-Example-Dataset}}\label{\detokenize{reddit-dataset-example::doc}}

\subsubsection{A walkthrough of the dataset code for the Big Graph Dataset project}
\label{\detokenize{reddit-dataset-example:A-walkthrough-of-the-dataset-code-for-the-Big-Graph-Dataset-project}}
\sphinxAtStartPar
Alex Davies, University of Bristol, 2024

\sphinxAtStartPar
In this notebook we’ll write code to:
\begin{itemize}
\item {} 
\sphinxAtStartPar
download a large Reddit graph from an online repository

\item {} 
\sphinxAtStartPar
sample that graph to produce a dataset of smaller graphs

\item {} 
\sphinxAtStartPar
process that dataset into a Pytorch Geometric InMemoryDataset

\end{itemize}


\bigskip\hrule\bigskip



\paragraph{Getting the graph}
\label{\detokenize{reddit-dataset-example:Getting-the-graph}}
\sphinxAtStartPar
First we need to download the graph, here from the \sphinxhref{http://snap.stanford.edu/data/soc-RedditHyperlinks.html}{Stanford Network Analysis Project}

\sphinxAtStartPar
We first find the links for the graph and node features (here node features are text embeddings):

\begin{sphinxuseclass}{nbinput}
\begin{sphinxuseclass}{nblast}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[1]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{graph\PYGZus{}url} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{https://snap.stanford.edu/data/soc\PYGZhy{}redditHyperlinks\PYGZhy{}title.tsv}\PYG{l+s+s2}{\PYGZdq{}}
\PYG{n}{embedding\PYGZus{}url} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{http://snap.stanford.edu/data/web\PYGZhy{}redditEmbeddings\PYGZhy{}subreddits.csv}\PYG{l+s+s2}{\PYGZdq{}}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Then play with directories and download the data:

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[2]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{import} \PYG{n+nn}{os}
\PYG{k+kn}{import} \PYG{n+nn}{pickle}
\PYG{k+kn}{import} \PYG{n+nn}{wget}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}

\PYG{c+c1}{\PYGZsh{} Swap into dataset directory}
\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{os}\PYG{o}{.}\PYG{n}{getcwd}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{start\PYGZus{}dir} \PYG{o}{=} \PYG{n}{os}\PYG{o}{.}\PYG{n}{getcwd}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{os}\PYG{o}{.}\PYG{n}{chdir}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{original\PYGZus{}datasets}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} We won\PYGZsq{}t actually need this part in the final function!}
\PYG{k}{if} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{reddit}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{not} \PYG{o+ow}{in} \PYG{n}{os}\PYG{o}{.}\PYG{n}{listdir}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{os}\PYG{o}{.}\PYG{n}{mkdir}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{reddit}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{n}{os}\PYG{o}{.}\PYG{n}{chdir}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{reddit}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{}  Download raw files if we don\PYGZsq{}t already have them}
\PYG{k}{if} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{soc\PYGZhy{}redditHyperlinks\PYGZhy{}title.tsv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{not} \PYG{o+ow}{in} \PYG{n}{os}\PYG{o}{.}\PYG{n}{listdir}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{graph\PYGZus{}data} \PYG{o}{=} \PYG{n}{wget}\PYG{o}{.}\PYG{n}{download}\PYG{p}{(}\PYG{n}{graph\PYGZus{}url}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Edgelist and edge features}
\PYG{k}{if} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZhy{}redditEmbeddings\PYGZhy{}subreddits.csv}\PYG{l+s+s2}{\PYGZdq{}} \PYG{o+ow}{not} \PYG{o+ow}{in} \PYG{n}{os}\PYG{o}{.}\PYG{n}{listdir}\PYG{p}{(}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{embedding\PYGZus{}data} \PYG{o}{=} \PYG{n}{wget}\PYG{o}{.}\PYG{n}{download}\PYG{p}{(}\PYG{n}{embedding\PYGZus{}url}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Node features}

\PYG{c+c1}{\PYGZsh{} We know that there are 300 components in the node feature vectors}
\PYG{n}{embedding\PYGZus{}column\PYGZus{}names} \PYG{o}{=} \PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{COMPONENT}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{o}{*}\PYG{p}{[}\PYG{n}{i} \PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{300}\PYG{p}{)}\PYG{p}{]}\PYG{p}{]}
\PYG{n}{embeddings} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{web\PYGZhy{}redditEmbeddings\PYGZhy{}subreddits.csv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{names}\PYG{o}{=}\PYG{n}{embedding\PYGZus{}column\PYGZus{}names}\PYG{p}{)}\PYG{o}{.}\PYG{n}{transpose}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{graph\PYGZus{}data} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{read\PYGZus{}csv}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{soc\PYGZhy{}redditHyperlinks\PYGZhy{}title.tsv}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{sep} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}t}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}


\PYG{c+c1}{\PYGZsh{} Avoids weird directory problems}
\PYG{n}{os}\PYG{o}{.}\PYG{n}{chdir}\PYG{p}{(}\PYG{n}{start\PYGZus{}dir}\PYG{p}{)}


\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
/home/alex/Projects/big-graph-dataset
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Let’s have a look at the node embeddings:

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[3]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{embeddings}\PYG{o}{.}\PYG{n}{head}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[3]:\,\hspace{\fboxrule}\hspace{\fboxsep}}              0          1                     2          3         4      \textbackslash{}
COMPONENT   spiders  askreddit  globaloffensivetrade  fireteams     funny
0          0.158972  -0.499114             -0.023145   2.492506  -0.81937
1          0.285813   0.323983             -1.199374  -2.529917 -0.865261
2          0.226329  -0.424809              1.661484  -0.448484  0.301753
3         -0.183338  -0.222705             -1.025296  -3.543441  0.018787

                5         6         7                8      \textbackslash{}
COMPONENT  the\_donald    videos      news  leagueoflegends
0           -0.123265  0.131896  0.132825        -2.785298
1           -0.610208  0.866419  1.505527        -0.166391
2            0.361495  0.919025  0.730393         1.592624
3           -1.171773 -0.765584 -0.505759        -1.269829

                          9      {\ldots}       51268               51269  \textbackslash{}
COMPONENT  rocketleagueexchange  {\ldots}  motleyfool  govtjobsrchinindia
0                      0.553341  {\ldots}    0.004494            0.001908
1                     -3.283354  {\ldots}    0.052268            0.042618
2                     -3.091485  {\ldots}   -0.027792           -0.021329
3                      0.877085  {\ldots}    0.013468               0.012

               51270     51271                51272     51273          51274  \textbackslash{}
COMPONENT  snoopdogg   fortean  whatcanidoforbernie      33rd  bestofvic2015
0          -0.000534  0.000615             0.000906 -0.000076      -0.000203
1           0.023619  0.023847             0.017816 -0.001643       0.012698
2          -0.003317 -0.018297            -0.004231 -0.002896      -0.007575
3           0.005566 -0.004873            -0.010438  0.000581       0.006486

                 51275            51276     51277
COMPONENT  aberystwyth  mail\_forwarding     cover
0            -0.001563         0.009269   0.00457
1             0.004733         0.024779  0.012403
2            -0.000082        -0.017018 -0.000363
3            -0.000982        -0.007228 -0.002496

[5 rows x 51278 columns]
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
And now the edges:

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[4]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n}{graph\PYGZus{}data}\PYG{o}{.}\PYG{n}{head}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[4]:\,\hspace{\fboxrule}\hspace{\fboxsep}}    SOURCE\_SUBREDDIT TARGET\_SUBREDDIT  POST\_ID            TIMESTAMP  \textbackslash{}
0         rddtgaming         rddtrust  1u4pzzs  2013-12-31 16:39:18
1            xboxone    battlefield\_4  1u4tmfs  2013-12-31 17:59:11
2                ps4    battlefield\_4  1u4tmos  2013-12-31 17:59:40
3  fitnesscirclejerk        leangains  1u50xfs  2013-12-31 19:01:56
4  fitnesscirclejerk      lifeprotips  1u51nps  2013-12-31 21:02:28

   LINK\_SENTIMENT                                         PROPERTIES
0               1  25.0,23.0,0.76,0.0,0.44,0.12,0.12,4.0,4.0,0.0,{\ldots}
1               1  100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,{\ldots}
2               1  100.0,88.0,0.78,0.02,0.08,0.13,0.07,16.0,16.0,{\ldots}
3               1  49.0,43.0,0.775510204082,0.0,0.265306122449,0{\ldots}
4               1  14.0,14.0,0.785714285714,0.0,0.428571428571,0{\ldots}
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\bigskip\hrule\bigskip



\paragraph{Turn the data into a graph}
\label{\detokenize{reddit-dataset-example:Turn-the-data-into-a-graph}}
\sphinxAtStartPar
Now we need to turn the data into a graph. Our edges come from graph\_data (SOURCE and TARGET), including categories for each edge (LINK\_SENTIMENT), as well as edge features (PROPERTIES).

\sphinxAtStartPar
The first step is making a networkx.Graph object, which is a useful graph class, then we add the nodes one by one. We’ll include the text embedding for the subreddit as a node attribute, taken from the embedding dataframe.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[5]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{c+c1}{\PYGZsh{} networkx is a Python library for graph structures}
\PYG{k+kn}{import} \PYG{n+nn}{networkx} \PYG{k}{as} \PYG{n+nn}{nx}
\PYG{c+c1}{\PYGZsh{} tqdm for loading bars}
\PYG{k+kn}{from} \PYG{n+nn}{tqdm} \PYG{k+kn}{import} \PYG{n}{tqdm}
\PYG{c+c1}{\PYGZsh{} cheeky function to visualise a networkx graph}
\PYG{k+kn}{from} \PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{vis\PYGZus{}networkx}

\PYG{n}{embeddings}\PYG{o}{.}\PYG{n}{columns} \PYG{o}{=} \PYG{n}{embeddings}\PYG{o}{.}\PYG{n}{iloc}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{embeddings} \PYG{o}{=} \PYG{n}{embeddings}\PYG{o}{.}\PYG{n}{drop}\PYG{p}{(}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{COMPONENT}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{,} \PYG{n}{axis} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{)}

\PYG{n}{graph} \PYG{o}{=} \PYG{n}{nx}\PYG{o}{.}\PYG{n}{Graph}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Add a node for each id in the embedding data}
\PYG{k}{for} \PYG{n}{col} \PYG{o+ow}{in} \PYG{n}{tqdm}\PYG{p}{(}\PYG{n}{embeddings}\PYG{o}{.}\PYG{n}{columns}\PYG{p}{,} \PYG{n}{desc} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Adding nodes}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{:}
    \PYG{c+c1}{\PYGZsh{} attrs here is taken from the embedding data, with the node id the column (col)}
    \PYG{n}{graph}\PYG{o}{.}\PYG{n}{add\PYGZus{}node}\PYG{p}{(}\PYG{n}{col}\PYG{p}{,} \PYG{n}{attrs}\PYG{o}{=}\PYG{n}{embeddings}\PYG{p}{[}\PYG{n}{col}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}numpy}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{n+nb}{float}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{rendered_html}


\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{nbsphinx-stderr}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{stderr}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Adding nodes: 100\%|██████████| 51278/51278 [00:01<00:00, 32961.66it/s]
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Now we add the edges (the actual graph stuff).

\sphinxAtStartPar
We need to include two properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Type of edge, negative or positive interaction, \sphinxhyphen{}1 or 1. In dataframe as LINK\_SENTIMENT

\item {} 
\sphinxAtStartPar
Properties of the edge, text embedding of the reddit post content

\end{itemize}

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[6]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}

\PYG{k}{def} \PYG{n+nf}{fix\PYGZus{}property\PYGZus{}string}\PYG{p}{(}\PYG{n}{input\PYGZus{}string}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{input\PYGZus{}string} \PYG{o}{=} \PYG{n}{input\PYGZus{}string}\PYG{o}{.}\PYG{n}{split}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{,}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{input\PYGZus{}string} \PYG{o}{=} \PYG{p}{[}\PYG{n+nb}{float}\PYG{p}{(}\PYG{n}{item}\PYG{p}{)} \PYG{k}{for} \PYG{n}{item} \PYG{o+ow}{in} \PYG{n}{input\PYGZus{}string}\PYG{p}{]}

    \PYG{k}{return} \PYG{n}{np}\PYG{o}{.}\PYG{n}{array}\PYG{p}{(}\PYG{n}{input\PYGZus{}string}\PYG{p}{)}

\PYG{n}{sources} \PYG{o}{=} \PYG{n}{graph\PYGZus{}data}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{SOURCE\PYGZus{}SUBREDDIT}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}numpy}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{targets} \PYG{o}{=} \PYG{n}{graph\PYGZus{}data}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{TARGET\PYGZus{}SUBREDDIT}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}numpy}\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} This line can take a while!}
\PYG{n}{attrs} \PYG{o}{=} \PYG{p}{[}\PYG{n}{fix\PYGZus{}property\PYGZus{}string}\PYG{p}{(}\PYG{n}{properties}\PYG{p}{)} \PYG{k}{for} \PYG{n}{properties} \PYG{o+ow}{in} \PYG{n}{tqdm}\PYG{p}{(}\PYG{n}{graph\PYGZus{}data}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{PROPERTIES}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{tolist}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{desc} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Wrangling edge features}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{nbsphinx-stderr}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{stderr}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Wrangling edge features: 100\%|██████████| 571927/571927 [00:05<00:00, 103705.47it/s]
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Now iterate over the edges, only adding them if their nodes have data:

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[7]:\,\hspace{\fboxrule}\hspace{\fboxsep}}
\PYG{n}{labels} \PYG{o}{=} \PYG{n}{graph\PYGZus{}data}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{LINK\PYGZus{}SENTIMENT}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{o}{.}\PYG{n}{to\PYGZus{}numpy}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{all\PYGZus{}nodes} \PYG{o}{=} \PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{graph}\PYG{o}{.}\PYG{n}{nodes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}

\PYG{k}{for} \PYG{n}{i} \PYG{o+ow}{in} \PYG{n}{tqdm}\PYG{p}{(}\PYG{n+nb}{range}\PYG{p}{(}\PYG{n}{sources}\PYG{o}{.}\PYG{n}{shape}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{n}{desc} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Adding edges}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{:}
    \PYG{c+c1}{\PYGZsh{} Check that the edge has data}
    \PYG{k}{if} \PYG{n}{sources}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o+ow}{in} \PYG{n}{all\PYGZus{}nodes} \PYG{o+ow}{and} \PYG{n}{targets}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o+ow}{in} \PYG{n}{all\PYGZus{}nodes}\PYG{p}{:}
        \PYG{n}{graph}\PYG{o}{.}\PYG{n}{add\PYGZus{}edge}\PYG{p}{(}\PYG{n}{sources}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{targets}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,}
                    \PYG{n}{labels} \PYG{o}{=} \PYG{n}{labels}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,}
                    \PYG{n}{attr} \PYG{o}{=} \PYG{n}{attrs}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{nbsphinx-stderr}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{stderr}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Adding edges: 100\%|██████████| 571927/571927 [00:37<00:00, 15434.45it/s]
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[8]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{n+nb}{print}\PYG{p}{(}\PYG{n}{graph}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Last tidying bits}
\PYG{n}{graph} \PYG{o}{=} \PYG{n}{nx}\PYG{o}{.}\PYG{n}{convert\PYGZus{}node\PYGZus{}labels\PYGZus{}to\PYGZus{}integers}\PYG{p}{(}\PYG{n}{graph}\PYG{p}{)}
\PYG{n}{CGs} \PYG{o}{=} \PYG{p}{[}\PYG{n}{graph}\PYG{o}{.}\PYG{n}{subgraph}\PYG{p}{(}\PYG{n}{c}\PYG{p}{)} \PYG{k}{for} \PYG{n}{c} \PYG{o+ow}{in} \PYG{n}{nx}\PYG{o}{.}\PYG{n}{connected\PYGZus{}components}\PYG{p}{(}\PYG{n}{graph}\PYG{p}{)}\PYG{p}{]}
\PYG{n}{CGs} \PYG{o}{=} \PYG{n+nb}{sorted}\PYG{p}{(}\PYG{n}{CGs}\PYG{p}{,} \PYG{n}{key}\PYG{o}{=}\PYG{k}{lambda} \PYG{n}{x}\PYG{p}{:} \PYG{n}{x}\PYG{o}{.}\PYG{n}{number\PYGZus{}of\PYGZus{}nodes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{reverse}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}
\PYG{n}{graph} \PYG{o}{=} \PYG{n}{CGs}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{graph} \PYG{o}{=} \PYG{n}{nx}\PYG{o}{.}\PYG{n}{convert\PYGZus{}node\PYGZus{}labels\PYGZus{}to\PYGZus{}integers}\PYG{p}{(}\PYG{n}{graph}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Save the graph!}
\PYG{k}{with} \PYG{n+nb}{open}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{original\PYGZus{}datasets/reddit/reddit\PYGZhy{}graph.npz}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{wb}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)} \PYG{k}{as} \PYG{n}{f}\PYG{p}{:}
    \PYG{n}{pickle}\PYG{o}{.}\PYG{n}{dump}\PYG{p}{(}\PYG{n}{graph}\PYG{p}{,} \PYG{n}{f}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Graph with 51278 nodes and 178143 edges
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Nice! Graph achieved. Spot that in the last section we had to deal with some missing data \sphinxhyphen{} we’re including edges ONLY if their nodes also have data.


\bigskip\hrule\bigskip



\subsubsection{Sample to make a dataset of smaller graphs}
\label{\detokenize{reddit-dataset-example:Sample-to-make-a-dataset-of-smaller-graphs}}
\sphinxAtStartPar
This is not too hard, I’ve written some code (Exploration Sampling With Replacement, ESWR) that does the sampling for you.

\sphinxAtStartPar
This will produce a big list of small networkx graphs sampled from that original graph.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[9]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{ESWR}

\PYG{c+c1}{\PYGZsh{} Sample 1000 graphs of max 96 nodes from the big reddit graph}
\PYG{n}{nx\PYGZus{}graph\PYGZus{}list} \PYG{o}{=} \PYG{n}{ESWR}\PYG{p}{(}\PYG{n}{graph}\PYG{p}{,} \PYG{l+m+mi}{1000}\PYG{p}{,} \PYG{l+m+mi}{96}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]

Sampling 1000 in 5 chunks with size 200
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{nbsphinx-stderr}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{stderr}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Sampling from large graph: 100\%|██████████| 6/6 [00:07<00:00,  1.31s/it]
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Done sampling!

\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{nbsphinx-stderr}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{stderr}


\begin{sphinxVerbatim}[commandchars=\\\{\}]

\end{sphinxVerbatim}

\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}
\sphinxAtStartPar
Next we need to convert it to a Pytorch Geometric format. This will be specific to your data \sphinxhyphen{} here we have node labels, edge labels, edge attributes.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[10]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{import} \PYG{n+nn}{torch}
\PYG{k+kn}{from} \PYG{n+nn}{torch\PYGZus{}geometric}\PYG{n+nn}{.}\PYG{n+nn}{data} \PYG{k+kn}{import} \PYG{n}{Data}

\PYG{k}{def} \PYG{n+nf}{specific\PYGZus{}from\PYGZus{}networkx}\PYG{p}{(}\PYG{n}{graph}\PYG{p}{)}\PYG{p}{:}
    \PYG{c+c1}{\PYGZsh{} Turns a graph into a pytorch geometric object}
    \PYG{c+c1}{\PYGZsh{} Mostly by unpacking dictionaries on nodes and edges}
    \PYG{c+c1}{\PYGZsh{} Here node labels are the target}
    \PYG{c+c1}{\PYGZsh{} One of these functions for each dataset ideally \PYGZhy{} they are unlikely to transfer across datasets}
    \PYG{n}{node\PYGZus{}attrs} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{n}{edge\PYGZus{}indices} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{n}{edge\PYGZus{}labels} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}
    \PYG{n}{edge\PYGZus{}attrs} \PYG{o}{=} \PYG{p}{[}\PYG{p}{]}

    \PYG{c+c1}{\PYGZsh{} Collect node labels and attributes}
    \PYG{k}{for} \PYG{n}{n} \PYG{o+ow}{in} \PYG{n+nb}{list}\PYG{p}{(}\PYG{n}{graph}\PYG{o}{.}\PYG{n}{nodes}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} list(graph.nodes(data=True)) returns [(node\PYGZus{}id1, \PYGZob{}attribute dictionary\PYGZcb{}), (node\PYGZus{}id2, ...), (node\PYGZus{}id3, ...)]}
        \PYG{n}{node\PYGZus{}attrs}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{torch}\PYG{o}{.}\PYG{n}{Tensor}\PYG{p}{(}\PYG{n}{n}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{attrs}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Collect edge indices and attributes}
    \PYG{k}{for} \PYG{n}{e} \PYG{o+ow}{in} \PYG{n}{graph}\PYG{o}{.}\PYG{n}{edges}\PYG{p}{(}\PYG{n}{data}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{)}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} graph.edges(data=True) is a generator producing (node\PYGZus{}id1, node\PYGZus{}id2, \PYGZob{}attribute dictionary\PYGZcb{})}
        \PYG{n}{edge\PYGZus{}indices}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{p}{(}\PYG{n}{e}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{e}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}

        \PYG{n}{edge\PYGZus{}attrs}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{torch}\PYG{o}{.}\PYG{n}{Tensor}\PYG{p}{(}\PYG{n}{e}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{attr}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
        \PYG{n}{edge\PYGZus{}labels}\PYG{o}{.}\PYG{n}{append}\PYG{p}{(}\PYG{n}{e}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{labels}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]}\PYG{p}{)}


    \PYG{c+c1}{\PYGZsh{} Specific to classification on edges! This is a binary edge classification (pos/neg) task}
    \PYG{n}{edge\PYGZus{}labels} \PYG{o}{=} \PYG{p}{(}\PYG{p}{(}\PYG{n}{torch}\PYG{o}{.}\PYG{n}{Tensor}\PYG{p}{(}\PYG{n}{edge\PYGZus{}labels}\PYG{p}{)} \PYG{o}{+} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{o}{/}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}

    \PYG{n}{edge\PYGZus{}attrs} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{(}\PYG{n}{edge\PYGZus{}attrs}\PYG{p}{)}
    \PYG{n}{node\PYGZus{}attrs} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{stack}\PYG{p}{(}\PYG{n}{node\PYGZus{}attrs}\PYG{p}{)}
    \PYG{n}{edge\PYGZus{}indices} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{tensor}\PYG{p}{(}\PYG{n}{edge\PYGZus{}indices}\PYG{p}{,} \PYG{n}{dtype}\PYG{o}{=}\PYG{n}{torch}\PYG{o}{.}\PYG{n}{long}\PYG{p}{)}\PYG{o}{.}\PYG{n}{t}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n}{contiguous}\PYG{p}{(}\PYG{p}{)}

    \PYG{c+c1}{\PYGZsh{} Create PyG Data object}
    \PYG{c+c1}{\PYGZsh{} Can pass:}
    \PYG{c+c1}{\PYGZsh{} x:            node features, shape (n nodes x n features)}
    \PYG{c+c1}{\PYGZsh{} edge\PYGZus{}index:   the list of edges in the graph, shape (2, n\PYGZus{}edges). Entries edge\PYGZus{}index[i, :] are [node\PYGZus{}id1, node\PYGZus{}id2].}
    \PYG{c+c1}{\PYGZsh{} edge\PYGZus{}attr:    edge features, shape (n\PYGZus{}edges, n\PYGZus{}features), same order as edgelist}
    \PYG{c+c1}{\PYGZsh{} y:            targets. Graph regression shape (n\PYGZus{}variables), graph classification (n\PYGZus{}classes), node classification (n\PYGZus{}nodes, n\PYGZus{}classes), edge classification (n\PYGZus{}edges, n\PYGZus{}classes)}
    \PYG{n}{data} \PYG{o}{=} \PYG{n}{Data}\PYG{p}{(}\PYG{n}{x}\PYG{o}{=}\PYG{n}{node\PYGZus{}attrs}\PYG{p}{,} \PYG{n}{edge\PYGZus{}index}\PYG{o}{=}\PYG{n}{edge\PYGZus{}indices}\PYG{p}{,} \PYG{n}{edge\PYGZus{}attr} \PYG{o}{=} \PYG{n}{edge\PYGZus{}attrs}\PYG{p}{,}  \PYG{n}{y}\PYG{o}{=}\PYG{n}{edge\PYGZus{}labels}\PYG{p}{)}

    \PYG{k}{return} \PYG{n}{data}

\PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Data in torch geometric format:}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
\PYG{n}{specific\PYGZus{}from\PYGZus{}networkx}\PYG{p}{(}\PYG{n}{nx\PYGZus{}graph\PYGZus{}list}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Data in torch geometric format:
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{nbsphinx-stderr}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{stderr}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
/home/alex/anaconda3/envs/adgcl/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user\_install.html
  from .autonotebook import tqdm as notebook\_tqdm
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxout}[10]:\,\hspace{\fboxrule}\hspace{\fboxsep}}Data(x=[54, 300], edge\_index=[2, 249], edge\_attr=[249, 86], y=[249, 1])
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\bigskip\hrule\bigskip



\subsubsection{The final dataset}
\label{\detokenize{reddit-dataset-example:The-final-dataset}}
\sphinxAtStartPar
Finally we place all that data into an InMemoryDataset!

\sphinxAtStartPar
Please note that in\sphinxhyphen{}code this whole notebook will be in functions \sphinxhyphen{} see \sphinxcode{\sphinxupquote{datasets/example\_dataset.py}}.

\sphinxAtStartPar
This means that the \sphinxcode{\sphinxupquote{datalist}} argument wouldn’t actually exist below \sphinxhyphen{} instead you’d call something like \sphinxcode{\sphinxupquote{get\_reddit\_dataset()}} within your \sphinxcode{\sphinxupquote{.process}} method.

\begin{sphinxuseclass}{nbinput}
{
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\llap{\color{nbsphinxin}[13]:\,\hspace{\fboxrule}\hspace{\fboxsep}}\PYG{k+kn}{from} \PYG{n+nn}{torch\PYGZus{}geometric}\PYG{n+nn}{.}\PYG{n+nn}{data} \PYG{k+kn}{import} \PYG{n}{InMemoryDataset}
\PYG{k+kn}{from} \PYG{n+nn}{utils} \PYG{k+kn}{import} \PYG{n}{vis\PYGZus{}grid}

\PYG{k}{class} \PYG{n+nc}{RedditDataset}\PYG{p}{(}\PYG{n}{InMemoryDataset}\PYG{p}{)}\PYG{p}{:}
\PYG{+w}{    }\PYG{l+s+sa}{r}\PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}}
\PYG{l+s+sd}{    Reddit hyperlink graphs \PYGZhy{} ie graphs of subreddits interacting with one another.}
\PYG{l+s+sd}{    The original graph is sourced from:}

\PYG{l+s+sd}{    `Kumar, Srijan, et al. \PYGZdq{}Community interaction and conflict on the web.\PYGZdq{} Proceedings of the 2018 world wide web conference. 2018.`}

\PYG{l+s+sd}{    The data has text embeddings as node features for each subreddit and text features for the cross\PYGZhy{}post edges.}

\PYG{l+s+sd}{    The task is edge classification for the sentiment of the interaction between subreddits.}

\PYG{l+s+sd}{    \PYGZhy{} Task: Edge classification}
\PYG{l+s+sd}{    \PYGZhy{} Num node features: 300}
\PYG{l+s+sd}{    \PYGZhy{} Num edge features: 86}
\PYG{l+s+sd}{    \PYGZhy{} Num target values: 1}
\PYG{l+s+sd}{    \PYGZhy{} Target shape: N Edges}
\PYG{l+s+sd}{    \PYGZhy{} Num graphs: Parameterised by `num`}

\PYG{l+s+sd}{    Args:}
\PYG{l+s+sd}{    root (str): Root directory where the dataset should be saved.}
\PYG{l+s+sd}{    datalist (list): A list of pytorch geometric data objects. Only obtained from an argument here, not in actual code!}
\PYG{l+s+sd}{    stage (str): The stage of the dataset to load. One of \PYGZdq{}train\PYGZdq{}, \PYGZdq{}val\PYGZdq{}, \PYGZdq{}test\PYGZdq{}. (default: :obj:`\PYGZdq{}train\PYGZdq{}`)}
\PYG{l+s+sd}{    transform (callable, optional): A function/transform that takes in an :obj:`torch\PYGZus{}geometric.data.Data` object and returns a transformed version. The data object will be transformed before every access. (default: :obj:`None`)}
\PYG{l+s+sd}{    pre\PYGZus{}transform (callable, optional): A function/transform that takes in an :obj:`torch\PYGZus{}geometric.data.Data` object and returns a transformed version. The data object will be transformed before being saved to disk. (default: :obj:`None`)}
\PYG{l+s+sd}{    pre\PYGZus{}filter (callable, optional): A function that takes in an :obj:`torch\PYGZus{}geometric.data.Data` object and returns a boolean value, indicating whether the data object should be included in the final dataset. (default: :obj:`None`)}
\PYG{l+s+sd}{    num (int): The number of samples to take from the original dataset. (default: :obj:`2000`).}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{c+c1}{\PYGZsh{} datalist is only an argument for this notebook example \PYGZhy{} see existing datasets under datasets/.. for how it actually works}
    \PYG{k}{def} \PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{,} \PYG{n}{root}\PYG{p}{,} \PYG{n}{datalist}\PYG{p}{,} \PYG{n}{stage} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{transform}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{pre\PYGZus{}transform}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{pre\PYGZus{}filter}\PYG{o}{=}\PYG{k+kc}{None}\PYG{p}{,} \PYG{n}{num} \PYG{o}{=} \PYG{l+m+mi}{2000}\PYG{p}{)}\PYG{p}{:}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{num} \PYG{o}{=} \PYG{n}{num}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{stage} \PYG{o}{=} \PYG{n}{stage}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{stage\PYGZus{}to\PYGZus{}index} \PYG{o}{=} \PYG{p}{\PYGZob{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{train}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}\PYG{l+m+mi}{0}\PYG{p}{,}
                               \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{val}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}\PYG{l+m+mi}{1}\PYG{p}{,}
                               \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{test}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{:}\PYG{l+m+mi}{2}\PYG{p}{\PYGZcb{}}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{datalist} \PYG{o}{=} \PYG{n}{datalist}

        \PYG{c+c1}{\PYGZsh{} Options are node\PYGZhy{}classification, node\PYGZhy{}regression, graph\PYGZhy{}classification, graph\PYGZhy{}regression, edge\PYGZhy{}regression, edge\PYGZhy{}classification}
        \PYG{c+c1}{\PYGZsh{} Graph\PYGZhy{}level tasks are preferred! (graph\PYGZhy{}classification and graph\PYGZhy{}regression)}
        \PYG{c+c1}{\PYGZsh{} edge\PYGZhy{}prediction is another option if you can\PYGZsq{}t think of a good task}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{task} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{node\PYGZhy{}classification}\PYG{l+s+s2}{\PYGZdq{}}

        \PYG{n+nb}{super}\PYG{p}{(}\PYG{p}{)}\PYG{o}{.}\PYG{n+nf+fm}{\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}}\PYG{p}{(}\PYG{n}{root}\PYG{p}{,} \PYG{n}{transform}\PYG{p}{,} \PYG{n}{pre\PYGZus{}transform}\PYG{p}{,} \PYG{n}{pre\PYGZus{}filter}\PYG{p}{)}
        \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{data}\PYG{p}{,} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{slices} \PYG{o}{=} \PYG{n}{torch}\PYG{o}{.}\PYG{n}{load}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{processed\PYGZus{}paths}\PYG{p}{[}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{stage\PYGZus{}to\PYGZus{}index}\PYG{p}{[}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{stage}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}


    \PYG{n+nd}{@property}
    \PYG{k}{def} \PYG{n+nf}{raw\PYGZus{}file\PYGZus{}names}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} Replace with your saved raw file name}
        \PYG{k}{return} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{reddit\PYGZhy{}graph.npz}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}

    \PYG{n+nd}{@property}
    \PYG{k}{def} \PYG{n+nf}{processed\PYGZus{}file\PYGZus{}names}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{k}{return} \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{train.pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{val.pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
                \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{test.pt}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}


    \PYG{k}{def} \PYG{n+nf}{process}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{p}{)}\PYG{p}{:}
        \PYG{c+c1}{\PYGZsh{} Read data into huge `Data` list.}

        \PYG{k}{if} \PYG{n}{os}\PYG{o}{.}\PYG{n}{path}\PYG{o}{.}\PYG{n}{isfile}\PYG{p}{(}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{processed\PYGZus{}paths}\PYG{p}{[}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{stage\PYGZus{}to\PYGZus{}index}\PYG{p}{[}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{stage}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
            \PYG{n+nb}{print}\PYG{p}{(}\PYG{l+s+sa}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Cora files exist}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
            \PYG{k}{return}

        \PYG{c+c1}{\PYGZsh{} Get a list of num pytorch\PYGZus{}geometric.data.Data objects}
        \PYG{n}{data\PYGZus{}list} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{datalist} \PYG{c+c1}{\PYGZsh{} get\PYGZus{}example\PYGZus{}dataset(num=self.num)}

        \PYG{c+c1}{\PYGZsh{} Torch geometric stuff}
        \PYG{k}{if} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{pre\PYGZus{}filter} \PYG{o+ow}{is} \PYG{o+ow}{not} \PYG{k+kc}{None}\PYG{p}{:}
            \PYG{n}{data\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{n}{data} \PYG{k}{for} \PYG{n}{data} \PYG{o+ow}{in} \PYG{n}{data\PYGZus{}list} \PYG{k}{if} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{pre\PYGZus{}filter}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)}\PYG{p}{]}

        \PYG{k}{if} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{pre\PYGZus{}transform} \PYG{o+ow}{is} \PYG{o+ow}{not} \PYG{k+kc}{None}\PYG{p}{:}
            \PYG{n}{data\PYGZus{}list} \PYG{o}{=} \PYG{p}{[}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{pre\PYGZus{}transform}\PYG{p}{(}\PYG{n}{data}\PYG{p}{)} \PYG{k}{for} \PYG{n}{data} \PYG{o+ow}{in} \PYG{n}{data\PYGZus{}list}\PYG{p}{]}

        \PYG{c+c1}{\PYGZsh{} Save data}
        \PYG{n}{data}\PYG{p}{,} \PYG{n}{slices} \PYG{o}{=} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{collate}\PYG{p}{(}\PYG{n}{data\PYGZus{}list}\PYG{p}{)}
        \PYG{n}{torch}\PYG{o}{.}\PYG{n}{save}\PYG{p}{(}\PYG{p}{(}\PYG{n}{data}\PYG{p}{,} \PYG{n}{slices}\PYG{p}{)}\PYG{p}{,} \PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{processed\PYGZus{}paths}\PYG{p}{[}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{stage\PYGZus{}to\PYGZus{}index}\PYG{p}{[}\PYG{n+nb+bp}{self}\PYG{o}{.}\PYG{n}{stage}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}

\PYG{n}{pyg\PYGZus{}graphs} \PYG{o}{=} \PYG{p}{[}\PYG{n}{specific\PYGZus{}from\PYGZus{}networkx}\PYG{p}{(}\PYG{n}{g}\PYG{p}{)} \PYG{k}{for} \PYG{n}{g} \PYG{o+ow}{in} \PYG{n}{tqdm}\PYG{p}{(}\PYG{n}{nx\PYGZus{}graph\PYGZus{}list}\PYG{p}{,} \PYG{n}{desc} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Converting data to PyG data objects}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{]}

\PYG{c+c1}{\PYGZsh{} The visualisation doesn\PYGZsq{}t work in documentation :( uncomment to see the graphs}
\PYG{n}{vis\PYGZus{}grid}\PYG{p}{(}\PYG{n}{pyg\PYGZus{}graphs}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{16}\PYG{p}{]}\PYG{p}{,} \PYG{n}{os}\PYG{o}{.}\PYG{n}{getcwd}\PYG{p}{(}\PYG{p}{)} \PYG{o}{+} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/original\PYGZus{}datasets/reddit/example.png}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{show\PYGZus{}plot} \PYG{o}{=} \PYG{k+kc}{True}\PYG{p}{)}

\PYG{n}{train\PYGZus{}dataset} \PYG{o}{=} \PYG{n}{RedditDataset}\PYG{p}{(}\PYG{n}{os}\PYG{o}{.}\PYG{n}{getcwd}\PYG{p}{(}\PYG{p}{)} \PYG{o}{+} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{/original\PYGZus{}datasets/reddit}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,}
                              \PYG{n}{pyg\PYGZus{}graphs}\PYG{p}{)}
\end{sphinxVerbatim}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{nbsphinx-stderr}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{stderr}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Converting data to PyG data objects: 100\%|██████████| 1000/1000 [00:01<00:00, 991.15it/s]
/home/alex/Projects/big-graph-dataset/utils.py:398: UserWarning: The figure layout has changed to tight
  plt.tight\_layout()
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\hrule height -\fboxrule\relax
\vspace{\nbsphinxcodecellspacing}

\makeatletter\setbox\nbsphinxpromptbox\box\voidb@x\makeatother

\begin{nbsphinxfancyoutput}

\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}
\noindent\sphinxincludegraphics[width=790\sphinxpxdimen,height=790\sphinxpxdimen]{{reddit-dataset-example_22_1}.png}

\end{sphinxuseclass}
\end{sphinxuseclass}
\end{nbsphinxfancyoutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{white}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Cora files exist
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\begin{sphinxuseclass}{nboutput}
\begin{sphinxuseclass}{nblast}
{

\kern-\sphinxverbatimsmallskipamount\kern-\baselineskip
\kern+\FrameHeightAdjust\kern-\fboxrule
\vspace{\nbsphinxcodecellspacing}

\sphinxsetup{VerbatimColor={named}{nbsphinx-stderr}}
\begin{sphinxuseclass}{output_area}
\begin{sphinxuseclass}{stderr}


\begin{sphinxVerbatim}[commandchars=\\\{\}]
Processing{\ldots}
Done!
\end{sphinxVerbatim}



\end{sphinxuseclass}
\end{sphinxuseclass}
}

\end{sphinxuseclass}
\end{sphinxuseclass}

\subsubsection{Other datsets}
\label{\detokenize{reddit-dataset-example:Other-datsets}}
\sphinxAtStartPar
There are already some datasets we can look at under datasets/DATASET.py.


\section{Datasets}
\label{\detokenize{index:datasets}}
\sphinxAtStartPar
Documentation for the datsets currently in the Big Graph Dataset project.

\sphinxstepscope


\subsection{Many\sphinxhyphen{}Graph Datasets}
\label{\detokenize{datasets:many-graph-datasets}}\label{\detokenize{datasets::doc}}
\sphinxAtStartPar
These datsets are composed of many small graphs.
Each is presented as a \sphinxtitleref{torch\_geometric.data.InMemoryDataset} object.

\sphinxAtStartPar
Tasks, node features and edge features vary between datasets.
Currently we don’t present dynamic graphs, multi\sphinxhyphen{}graphs or temporal graphs.

\sphinxAtStartPar
Additionally the functions \sphinxtitleref{get\_X\_datasets()} retrieve multiple datasets at once.
\index{module@\spxentry{module}!datasets@\spxentry{datasets}}\index{datasets@\spxentry{datasets}!module@\spxentry{module}}\index{CoraDataset (class in datasets)@\spxentry{CoraDataset}\spxextra{class in datasets}}\phantomsection\label{\detokenize{datasets:module-datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.CoraDataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{CoraDataset}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{InMemoryDataset}}

\sphinxAtStartPar
Academic citation graphs from the ML community, sampled from a large original graph using ESWR.
The original graph is sourced from:
\begin{quote}

\sphinxAtStartPar
\sphinxtitleref{Yang, Zhilin, William Cohen, and Ruslan Salakhudinov. “Revisiting semi\sphinxhyphen{}supervised learning with graph embeddings.” International conference on machine learning. PMLR, 2016.}
\end{quote}

\sphinxAtStartPar
The original data has one\sphinxhyphen{}hot bag\sphinxhyphen{}of\sphinxhyphen{}words over paper abstract as node features.

\sphinxAtStartPar
The task is node classification for the category of each paper, one\sphinxhyphen{}hot encoded for seven categories.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Task: Node classification

\item {} 
\sphinxAtStartPar
Num node features: 2879

\item {} 
\sphinxAtStartPar
Num edge features: None

\item {} 
\sphinxAtStartPar
Num target values: 7

\item {} 
\sphinxAtStartPar
Target shape: N Nodes

\item {} 
\sphinxAtStartPar
Num graphs: Parameterised by \sphinxtitleref{num}

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{root}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – Root directory where the dataset should be saved.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stage}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – The stage of the dataset to load. One of “train”, “val”, “test”. (default: \sphinxcode{\sphinxupquote{"train"}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before every access. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before being saved to disk. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_filter}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a boolean value, indicating whether the data object should be included in the final dataset. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) – The number of samples to take from the original dataset. (default: \sphinxcode{\sphinxupquote{2000}}).

\end{itemize}

\end{description}\end{quote}
\index{\_\_init\_\_() (datasets.CoraDataset method)@\spxentry{\_\_init\_\_()}\spxextra{datasets.CoraDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.CoraDataset.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{\_abc\_impl (datasets.CoraDataset attribute)@\spxentry{\_abc\_impl}\spxextra{datasets.CoraDataset attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.CoraDataset._abc_impl}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{\_abc\_impl}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{ }\DUrole{p}{=}\DUrole{w}{ }<\_abc.\_abc\_data object>}}}
\pysigstopsignatures
\end{fulllineitems}

\index{process() (datasets.CoraDataset method)@\spxentry{process()}\spxextra{datasets.CoraDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.CoraDataset.process}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{processed\_file\_names (datasets.CoraDataset property)@\spxentry{processed\_file\_names}\spxextra{datasets.CoraDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.CoraDataset.processed_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{processed\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}

\index{raw\_file\_names (datasets.CoraDataset property)@\spxentry{raw\_file\_names}\spxextra{datasets.CoraDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.CoraDataset.raw_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{raw\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{EgoDataset (class in datasets)@\spxentry{EgoDataset}\spxextra{class in datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.EgoDataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{EgoDataset}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{5000}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{InMemoryDataset}}

\sphinxAtStartPar
Ego networks from the streaming platform Twitch.
The original graph is sourced from:
\begin{quote}

\sphinxAtStartPar
\sphinxtitleref{B. Rozemberczki, O. Kiss, R. Sarkar: An API Oriented Open\sphinxhyphen{}source Python Framework for Unsupervised Learning on Graphs 2019.}
\end{quote}

\sphinxAtStartPar
The task is predicting whether a given streamer plays multiple different games.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Task: Graph classification

\item {} 
\sphinxAtStartPar
Num node features: None

\item {} 
\sphinxAtStartPar
Num edge features: None

\item {} 
\sphinxAtStartPar
Num target values: 1

\item {} 
\sphinxAtStartPar
Target shape: 1

\item {} 
\sphinxAtStartPar
Num graphs: 127094

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{root}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – Root directory where the dataset should be saved.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stage}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – The stage of the dataset to load. One of “train”, “val”, “test”. (default: \sphinxcode{\sphinxupquote{"train"}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before every access. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before being saved to disk. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_filter}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a boolean value, indicating whether the data object should be included in the final dataset. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) – The number of samples to take from the original dataset. (default: \sphinxcode{\sphinxupquote{2000}}).

\end{itemize}

\end{description}\end{quote}
\index{\_\_init\_\_() (datasets.EgoDataset method)@\spxentry{\_\_init\_\_()}\spxextra{datasets.EgoDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.EgoDataset.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{5000}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{\_abc\_impl (datasets.EgoDataset attribute)@\spxentry{\_abc\_impl}\spxextra{datasets.EgoDataset attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.EgoDataset._abc_impl}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{\_abc\_impl}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{ }\DUrole{p}{=}\DUrole{w}{ }<\_abc.\_abc\_data object>}}}
\pysigstopsignatures
\end{fulllineitems}

\index{process() (datasets.EgoDataset method)@\spxentry{process()}\spxextra{datasets.EgoDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.EgoDataset.process}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{processed\_file\_names (datasets.EgoDataset property)@\spxentry{processed\_file\_names}\spxextra{datasets.EgoDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.EgoDataset.processed_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{processed\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}

\index{raw\_file\_names (datasets.EgoDataset property)@\spxentry{raw\_file\_names}\spxextra{datasets.EgoDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.EgoDataset.raw_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{raw\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{FacebookDataset (class in datasets)@\spxentry{FacebookDataset}\spxextra{class in datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.FacebookDataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{FacebookDataset}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{InMemoryDataset}}

\sphinxAtStartPar
Facebook page\sphinxhyphen{}to\sphinxhyphen{}page interaction graphs, sampled from a large original graph using ESWR.
The original graph is sourced from:
\begin{quote}

\sphinxAtStartPar
\sphinxtitleref{Benedek Rozemberczki, Carl Allen, and Rik Sarkar. Multi\sphinxhyphen{}Scale Attributed Node Embedding.  Journal of Complex Networks 2021}
\end{quote}

\sphinxAtStartPar
The original data has node features, but as they are of varying length, we don’t include them here.

\sphinxAtStartPar
The task is node classification for the category of each Facebook page in a given graph, one\sphinxhyphen{}hot encoded for four categories.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Task: Node classification

\item {} 
\sphinxAtStartPar
Num node features: None

\item {} 
\sphinxAtStartPar
Num edge features: None

\item {} 
\sphinxAtStartPar
Num target values: 4

\item {} 
\sphinxAtStartPar
Target shape: N Nodes

\item {} 
\sphinxAtStartPar
Num graphs: Parameterised by \sphinxtitleref{num}

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{root}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – Root directory where the dataset should be saved.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stage}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – The stage of the dataset to load. One of “train”, “val”, “test”. (default: \sphinxcode{\sphinxupquote{"train"}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before every access. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before being saved to disk. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_filter}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a boolean value, indicating whether the data object should be included in the final dataset. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) – The number of samples to take from the original dataset. (default: \sphinxcode{\sphinxupquote{2000}}).

\end{itemize}

\end{description}\end{quote}
\index{\_\_init\_\_() (datasets.FacebookDataset method)@\spxentry{\_\_init\_\_()}\spxextra{datasets.FacebookDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.FacebookDataset.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{\_abc\_impl (datasets.FacebookDataset attribute)@\spxentry{\_abc\_impl}\spxextra{datasets.FacebookDataset attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.FacebookDataset._abc_impl}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{\_abc\_impl}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{ }\DUrole{p}{=}\DUrole{w}{ }<\_abc.\_abc\_data object>}}}
\pysigstopsignatures
\end{fulllineitems}

\index{process() (datasets.FacebookDataset method)@\spxentry{process()}\spxextra{datasets.FacebookDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.FacebookDataset.process}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{processed\_file\_names (datasets.FacebookDataset property)@\spxentry{processed\_file\_names}\spxextra{datasets.FacebookDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.FacebookDataset.processed_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{processed\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}

\index{raw\_file\_names (datasets.FacebookDataset property)@\spxentry{raw\_file\_names}\spxextra{datasets.FacebookDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.FacebookDataset.raw_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{raw\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{NeuralDataset (class in datasets)@\spxentry{NeuralDataset}\spxextra{class in datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.NeuralDataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{NeuralDataset}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{InMemoryDataset}}

\sphinxAtStartPar
A dataset of the connectome of a fruit fly larvae.
The original graph is sourced from:
\begin{quote}

\sphinxAtStartPar
\sphinxtitleref{Michael Winding et al. , The connectome of an insect brain.Science379,eadd9330(2023).DOI:10.1126/science.add9330}
\end{quote}

\sphinxAtStartPar
We process the original multigraph into ESWR samples of this neural network, with predicting the strength of the connection (number of synapses) between two neurons as the target.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Task: Edge regression

\item {} 
\sphinxAtStartPar
Num node features: 0

\item {} 
\sphinxAtStartPar
Num edge features: 0

\item {} 
\sphinxAtStartPar
Num target values: 1

\item {} 
\sphinxAtStartPar
Target shape: N Edges

\item {} 
\sphinxAtStartPar
Num graphs: Parameterised by \sphinxtitleref{num}

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{root}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – Root directory where the dataset should be saved.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stage}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – The stage of the dataset to load. One of “train”, “val”, “test”. (default: \sphinxcode{\sphinxupquote{"train"}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before every access. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before being saved to disk. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_filter}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a boolean value, indicating whether the data object should be included in the final dataset. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) – The number of samples to take from the original dataset. (default: \sphinxcode{\sphinxupquote{2000}}).

\end{itemize}

\end{description}\end{quote}
\index{\_\_init\_\_() (datasets.NeuralDataset method)@\spxentry{\_\_init\_\_()}\spxextra{datasets.NeuralDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.NeuralDataset.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{\_abc\_impl (datasets.NeuralDataset attribute)@\spxentry{\_abc\_impl}\spxextra{datasets.NeuralDataset attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.NeuralDataset._abc_impl}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{\_abc\_impl}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{ }\DUrole{p}{=}\DUrole{w}{ }<\_abc.\_abc\_data object>}}}
\pysigstopsignatures
\end{fulllineitems}

\index{process() (datasets.NeuralDataset method)@\spxentry{process()}\spxextra{datasets.NeuralDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.NeuralDataset.process}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{processed\_file\_names (datasets.NeuralDataset property)@\spxentry{processed\_file\_names}\spxextra{datasets.NeuralDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.NeuralDataset.processed_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{processed\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}

\index{raw\_file\_names (datasets.NeuralDataset property)@\spxentry{raw\_file\_names}\spxextra{datasets.NeuralDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.NeuralDataset.raw_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{raw\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{RedditDataset (class in datasets)@\spxentry{RedditDataset}\spxextra{class in datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RedditDataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{RedditDataset}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{InMemoryDataset}}

\sphinxAtStartPar
Reddit hyperlink graphs \sphinxhyphen{} ie graphs of subreddits interacting with one another.
The original graph is sourced from:
\begin{quote}

\sphinxAtStartPar
\sphinxtitleref{Kumar, Srijan, et al. “Community interaction and conflict on the web.” Proceedings of the 2018 world wide web conference. 2018.}
\end{quote}

\sphinxAtStartPar
The data has text embeddings as node features for each subreddit and text features for the cross\sphinxhyphen{}post edges.

\sphinxAtStartPar
The task is edge classification for the sentiment of the interaction between subreddits.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Task: Edge classification

\item {} 
\sphinxAtStartPar
Num node features: 300

\item {} 
\sphinxAtStartPar
Num edge features: 86

\item {} 
\sphinxAtStartPar
Num target values: 1

\item {} 
\sphinxAtStartPar
Target shape: N Edges

\item {} 
\sphinxAtStartPar
Num graphs: Parameterised by \sphinxtitleref{num}

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{root}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – Root directory where the dataset should be saved.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stage}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – The stage of the dataset to load. One of “train”, “val”, “test”. (default: \sphinxcode{\sphinxupquote{"train"}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before every access. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before being saved to disk. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_filter}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a boolean value, indicating whether the data object should be included in the final dataset. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) – The number of samples to take from the original dataset. (default: \sphinxcode{\sphinxupquote{2000}}).

\end{itemize}

\end{description}\end{quote}
\index{\_\_init\_\_() (datasets.RedditDataset method)@\spxentry{\_\_init\_\_()}\spxextra{datasets.RedditDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RedditDataset.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{\_abc\_impl (datasets.RedditDataset attribute)@\spxentry{\_abc\_impl}\spxextra{datasets.RedditDataset attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RedditDataset._abc_impl}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{\_abc\_impl}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{ }\DUrole{p}{=}\DUrole{w}{ }<\_abc.\_abc\_data object>}}}
\pysigstopsignatures
\end{fulllineitems}

\index{process() (datasets.RedditDataset method)@\spxentry{process()}\spxextra{datasets.RedditDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RedditDataset.process}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{processed\_file\_names (datasets.RedditDataset property)@\spxentry{processed\_file\_names}\spxextra{datasets.RedditDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RedditDataset.processed_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{processed\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}

\index{raw\_file\_names (datasets.RedditDataset property)@\spxentry{raw\_file\_names}\spxextra{datasets.RedditDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RedditDataset.raw_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{raw\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{RoadDataset (class in datasets)@\spxentry{RoadDataset}\spxextra{class in datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RoadDataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{RoadDataset}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{InMemoryDataset}}

\sphinxAtStartPar
Road graphs from Pennsylvania, sampled from a large original graph using ESWR.
The original graph is sourced from:
\begin{quote}

\sphinxAtStartPar
\sphinxtitleref{J. Leskovec, K. Lang, A. Dasgupta, M. Mahoney. Community Structure in Large Networks: Natural Cluster Sizes and the Absence of Large Well\sphinxhyphen{}Defined Clusters. Internet Mathematics 6(1) 29–123, 2009.}
\end{quote}

\sphinxAtStartPar
The task is predicting whether a given graph is planar (can be laid out with no crossing edges).
\begin{itemize}
\item {} 
\sphinxAtStartPar
Task: Graph classification

\item {} 
\sphinxAtStartPar
Num node features: None

\item {} 
\sphinxAtStartPar
Num edge features: None

\item {} 
\sphinxAtStartPar
Num target values: 1

\item {} 
\sphinxAtStartPar
Target shape: 1

\item {} 
\sphinxAtStartPar
Num graphs: Parameterised by \sphinxtitleref{num}

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{root}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – Root directory where the dataset should be saved.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stage}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – The stage of the dataset to load. One of “train”, “val”, “test”. (default: \sphinxcode{\sphinxupquote{"train"}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before every access. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before being saved to disk. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_filter}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a boolean value, indicating whether the data object should be included in the final dataset. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) – The number of samples to take from the original dataset. (default: \sphinxcode{\sphinxupquote{2000}}).

\end{itemize}

\end{description}\end{quote}
\index{\_\_init\_\_() (datasets.RoadDataset method)@\spxentry{\_\_init\_\_()}\spxextra{datasets.RoadDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RoadDataset.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{stage}\DUrole{o}{=}\DUrole{default_value}{'train'}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{\_abc\_impl (datasets.RoadDataset attribute)@\spxentry{\_abc\_impl}\spxextra{datasets.RoadDataset attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RoadDataset._abc_impl}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{\_abc\_impl}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{ }\DUrole{p}{=}\DUrole{w}{ }<\_abc.\_abc\_data object>}}}
\pysigstopsignatures
\end{fulllineitems}

\index{process() (datasets.RoadDataset method)@\spxentry{process()}\spxextra{datasets.RoadDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RoadDataset.process}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{processed\_file\_names (datasets.RoadDataset property)@\spxentry{processed\_file\_names}\spxextra{datasets.RoadDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RoadDataset.processed_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{processed\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}

\index{raw\_file\_names (datasets.RoadDataset property)@\spxentry{raw\_file\_names}\spxextra{datasets.RoadDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.RoadDataset.raw_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{raw\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{get\_all\_datasets() (in module datasets)@\spxentry{get\_all\_datasets()}\spxextra{in module datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.get_all_datasets}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{get\_all\_datasets}}}{\sphinxparam{\DUrole{n}{transforms}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{5000}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mol\_only}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get all datasets for training and validation, in that order.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transforms}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) – List of data transformations to apply to the datasets.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – Number of samples to load from each dataset. Defaults to 5000.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mol\_only}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – Flag indicating whether to include only chemical datasets. Defaults to False.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{description}
\sphinxlineitem{A tuple containing two elements:}\begin{itemize}
\item {} 
\sphinxAtStartPar
datasets (list): A list of all the datasets.

\item {} 
\sphinxAtStartPar
all\_names (list): A list of names corresponding to each dataset.

\end{itemize}

\end{description}


\sphinxlineitem{Return type}
\sphinxAtStartPar
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_test\_datasets() (in module datasets)@\spxentry{get\_test\_datasets()}\spxextra{in module datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.get_test_datasets}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{get\_test\_datasets}}}{\sphinxparam{\DUrole{n}{transforms}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mol\_only}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get the test split of each dataset.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transforms}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) – List of data transformations to apply.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) – Number of samples in datasets to include (default is 2000).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mol\_only}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) – Flag indicating whether to include only chemical datasets (default is False).

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{description}
\sphinxlineitem{A tuple containing two elements:}\begin{itemize}
\item {} 
\sphinxAtStartPar
datasets (list): List of test datasets.

\item {} 
\sphinxAtStartPar
names (list): List of dataset names.

\end{itemize}

\end{description}


\sphinxlineitem{Return type}
\sphinxAtStartPar
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_train\_datasets() (in module datasets)@\spxentry{get\_train\_datasets()}\spxextra{in module datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.get_train_datasets}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{get\_train\_datasets}}}{\sphinxparam{\DUrole{n}{transforms}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mol\_only}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get the training splits of each dataset.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transforms}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) – List of data transformations to apply.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) – Number of datasets to retrieve.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mol\_only}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) – Flag indicating whether to retrieve only chemical datasets.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{description}
\sphinxlineitem{A tuple containing two elements:}\begin{itemize}
\item {} 
\sphinxAtStartPar
datasets (list): A list of all the datasets.

\item {} 
\sphinxAtStartPar
all\_names (list): A list of names corresponding to each dataset.

\end{itemize}

\end{description}


\sphinxlineitem{Return type}
\sphinxAtStartPar
tuple

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_val\_datasets() (in module datasets)@\spxentry{get\_val\_datasets()}\spxextra{in module datasets}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{datasets:datasets.get_val_datasets}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{datasets.}}\sphinxbfcode{\sphinxupquote{get\_val\_datasets}}}{\sphinxparam{\DUrole{n}{transforms}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{2000}}\sphinxparamcomma \sphinxparam{\DUrole{n}{mol\_only}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get validation splits for each dataset.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transforms}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) – List of data transformations to apply.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – Number of samples in datasets to include. Defaults to 2000.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mol\_only}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – Flag indicating whether to include only chemical datasets. Defaults to False.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{description}
\sphinxlineitem{A tuple containing two elements:}\begin{itemize}
\item {} 
\sphinxAtStartPar
datasets (list): List of validation datasets.

\item {} 
\sphinxAtStartPar
names (list): List of dataset names.

\end{itemize}

\end{description}


\sphinxlineitem{Return type}
\sphinxAtStartPar
tuple

\end{description}\end{quote}

\end{fulllineitems}



\section{ToP (Topology Only Pre\sphinxhyphen{}Training)}
\label{\detokenize{index:top-topology-only-pre-training}}
\sphinxAtStartPar
Documentation for the Topology Only Pre\sphinxhyphen{}Training component of the project.
We are using a pre\sphinxhyphen{}trained model to generate embeddings of the graphs in the datasets, hopefully to get some measure of how diverse the datasets are.
Very much a work\sphinxhyphen{}in\sphinxhyphen{}progress!

\sphinxstepscope


\subsection{ToP (Topology only Pre\sphinxhyphen{}training)}
\label{\detokenize{top:module-top}}\label{\detokenize{top:top-topology-only-pre-training}}\label{\detokenize{top::doc}}\index{module@\spxentry{module}!top@\spxentry{top}}\index{top@\spxentry{top}!module@\spxentry{module}}\index{GeneralEmbeddingEvaluation (class in top)@\spxentry{GeneralEmbeddingEvaluation}\spxextra{class in top}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.GeneralEmbeddingEvaluation}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{top.}}\sphinxbfcode{\sphinxupquote{GeneralEmbeddingEvaluation}}}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
Class for evaluating embeddings and visualizing the results.
\index{\_\_init\_\_() (top.GeneralEmbeddingEvaluation method)@\spxentry{\_\_init\_\_()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.GeneralEmbeddingEvaluation.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Initializes the GeneralEmbeddingEvaluation object.

\end{fulllineitems}

\index{embedding\_evaluation() (top.GeneralEmbeddingEvaluation method)@\spxentry{embedding\_evaluation()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.GeneralEmbeddingEvaluation.embedding_evaluation}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{embedding\_evaluation}}}{\sphinxparam{\DUrole{n}{encoder}}\sphinxparamcomma \sphinxparam{\DUrole{n}{train\_loaders}}\sphinxparamcomma \sphinxparam{\DUrole{n}{names}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Performs embedding evaluation using the given encoder, train loaders, and names.

\end{fulllineitems}

\index{get\_embeddings() (top.GeneralEmbeddingEvaluation method)@\spxentry{get\_embeddings()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.GeneralEmbeddingEvaluation.get_embeddings}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_embeddings}}}{\sphinxparam{\DUrole{n}{encoder}}\sphinxparamcomma \sphinxparam{\DUrole{n}{loaders}}\sphinxparamcomma \sphinxparam{\DUrole{n}{names}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Retrieves the embeddings from the encoder and loaders.

\end{fulllineitems}

\index{vis() (top.GeneralEmbeddingEvaluation method)@\spxentry{vis()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.GeneralEmbeddingEvaluation.vis}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{vis}}}{\sphinxparam{\DUrole{n}{all\_embeddings}}\sphinxparamcomma \sphinxparam{\DUrole{n}{separate\_embeddings}}\sphinxparamcomma \sphinxparam{\DUrole{n}{names}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Visualizes the embeddings using UMAP and PCA projections.

\end{fulllineitems}

\index{centroid\_similarities() (top.GeneralEmbeddingEvaluation method)@\spxentry{centroid\_similarities()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.GeneralEmbeddingEvaluation.centroid_similarities}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{centroid\_similarities}}}{\sphinxparam{\DUrole{n}{embeddings}}\sphinxparamcomma \sphinxparam{\DUrole{n}{names}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculates the pairwise similarities between the centroids of the embeddings.

\end{fulllineitems}

\index{\_\_init\_\_() (top.GeneralEmbeddingEvaluation method)@\spxentry{\_\_init\_\_()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:id0}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{centroid\_similarities() (top.GeneralEmbeddingEvaluation method)@\spxentry{centroid\_similarities()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:id1}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{centroid\_similarities}}}{\sphinxparam{\DUrole{n}{embeddings}}\sphinxparamcomma \sphinxparam{\DUrole{n}{names}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculate centroid similarities for a given set of embeddings and names.

\sphinxAtStartPar
Parameters:
embeddings (list of numpy arrays): List of embeddings, where each embedding is a numpy array.
names (list of str): List of names corresponding to the embeddings.

\sphinxAtStartPar
Returns:
None

\sphinxAtStartPar
This method calculates the centroid similarities for a given set of embeddings. It first calculates the centroid
for each embedding by taking the mean along the axis 0. Then, it calculates the pairwise similarities between
the centroids using cosine similarity. Finally, it visualizes the pairwise similarities as a heatmap and saves
the plot as “outputs/pairwise\sphinxhyphen{}similarity.png”.

\end{fulllineitems}

\index{embedding\_evaluation() (top.GeneralEmbeddingEvaluation method)@\spxentry{embedding\_evaluation()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:id2}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{embedding\_evaluation}}}{\sphinxparam{\DUrole{n}{encoder}}\sphinxparamcomma \sphinxparam{\DUrole{n}{train\_loaders}}\sphinxparamcomma \sphinxparam{\DUrole{n}{names}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Evaluate the embeddings generated by the encoder.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{encoder}} – The encoder model used to generate the embeddings.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{train\_loaders}} – A list of data loaders for the data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{names}} – A list of names corresponding to the data loaders.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_embeddings() (top.GeneralEmbeddingEvaluation method)@\spxentry{get\_embeddings()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:id3}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_embeddings}}}{\sphinxparam{\DUrole{n}{encoder}}\sphinxparamcomma \sphinxparam{\DUrole{n}{loaders}}\sphinxparamcomma \sphinxparam{\DUrole{n}{names}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get embeddings for the given encoder and loaders.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{encoder}} – The encoder model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{loaders}} – A list of data loaders.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{names}} – A list of names corresponding to the loaders.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
A tuple containing the concatenated embeddings of all loaders and a list of separate embeddings for each loader.

\end{description}\end{quote}

\end{fulllineitems}

\index{vis() (top.GeneralEmbeddingEvaluation method)@\spxentry{vis()}\spxextra{top.GeneralEmbeddingEvaluation method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:id4}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{vis}}}{\sphinxparam{\DUrole{n}{all\_embeddings}}\sphinxparamcomma \sphinxparam{\DUrole{n}{separate\_embeddings}}\sphinxparamcomma \sphinxparam{\DUrole{n}{names}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Visualizes the embeddings using UMAP and PCA projections.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{all\_embeddings}} (\sphinxstyleliteralemphasis{\sphinxupquote{numpy.ndarray}}) – The combined embeddings of all graphs.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{separate\_embeddings}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) – A list of separate embeddings for each graph.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{names}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) – A list of names corresponding to each graph.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{ToPDataset (class in top)@\spxentry{ToPDataset}\spxextra{class in top}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.ToPDataset}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{ }}}\sphinxcode{\sphinxupquote{top.}}\sphinxbfcode{\sphinxupquote{ToPDataset}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{original\_dataset}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{}1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{InMemoryDataset}}

\sphinxAtStartPar
Processes an InMemoryDataset into a ToP dataset by removing node and edge features.

\sphinxAtStartPar
Based on the paper:
\begin{quote}

\sphinxAtStartPar
\sphinxtitleref{Towards Generalised Pre\sphinxhyphen{}Training of Graph Models, Davies, A. O., Green, R. W., Ajmeri, N. S., and Silva Filho, T. M.,  arXiv e\sphinxhyphen{}prints, 2024. doi:10.48550/arXiv.2311.03976.}
\end{quote}

\sphinxAtStartPar
The resulting dataset is topology\sphinxhyphen{}only, intended for pre\sphinxhyphen{}training with ToP, and as such this module does not produce validation/test splits.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{root}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) – Root directory where the dataset should be saved. The dataset will be saved in \sphinxtitleref{root}/train\sphinxhyphen{}top.pt

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{original\_dataset}} (\sphinxstyleliteralemphasis{\sphinxupquote{InMemoryDataset}}) – The original dataset to convert to ToP format.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) – The number of samples to take from the original dataset. \sphinxtitleref{num=\sphinxhyphen{}1} will convert all available samples from the original. (default: \sphinxcode{\sphinxupquote{\sphinxhyphen{}1}}).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before every access. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_transform}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function/transform that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a transformed version. The data object will be transformed before being saved to disk. (default: \sphinxcode{\sphinxupquote{None}})

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{pre\_filter}} (\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{optional}}) – A function that takes in an \sphinxcode{\sphinxupquote{torch\_geometric.data.Data}} object and returns a boolean value, indicating whether the data object should be included in the final dataset. (default: \sphinxcode{\sphinxupquote{None}})

\end{itemize}

\end{description}\end{quote}
\index{\_\_init\_\_() (top.ToPDataset method)@\spxentry{\_\_init\_\_()}\spxextra{top.ToPDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.ToPDataset.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\sphinxparam{\DUrole{n}{root}}\sphinxparamcomma \sphinxparam{\DUrole{n}{original\_dataset}}\sphinxparamcomma \sphinxparam{\DUrole{n}{num}\DUrole{o}{=}\DUrole{default_value}{\sphinxhyphen{}1}}\sphinxparamcomma \sphinxparam{\DUrole{n}{transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_transform}\DUrole{o}{=}\DUrole{default_value}{None}}\sphinxparamcomma \sphinxparam{\DUrole{n}{pre\_filter}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{\_abc\_impl (top.ToPDataset attribute)@\spxentry{\_abc\_impl}\spxextra{top.ToPDataset attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.ToPDataset._abc_impl}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{\_abc\_impl}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{ }\DUrole{p}{=}\DUrole{w}{ }<\_abc.\_abc\_data object>}}}
\pysigstopsignatures
\end{fulllineitems}

\index{process() (top.ToPDataset method)@\spxentry{process()}\spxextra{top.ToPDataset method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.ToPDataset.process}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{process}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{processed\_file\_names (top.ToPDataset property)@\spxentry{processed\_file\_names}\spxextra{top.ToPDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.ToPDataset.processed_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{processed\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}

\index{raw\_file\_names (top.ToPDataset property)@\spxentry{raw\_file\_names}\spxextra{top.ToPDataset property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.ToPDataset.raw_file_names}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{ }}}\sphinxbfcode{\sphinxupquote{raw\_file\_names}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{compute\_top\_scores() (in module top)@\spxentry{compute\_top\_scores()}\spxextra{in module top}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{top:top.compute_top_scores}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{top.}}\sphinxbfcode{\sphinxupquote{compute\_top\_scores}}}{\sphinxparam{\DUrole{n}{datasets}}\sphinxparamcomma \sphinxparam{\DUrole{n}{names}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Computes the top scores for graph structures using the ToP encoder.

\sphinxAtStartPar
ToP scores use a pre\sphinxhyphen{}trained ToP model to compute the similarity between graphs across datasets.

\sphinxAtStartPar
This function will also produce embedding visualisations using GeneralEmbeddingEvaluation.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{datasets}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) – A list of datasets containing graph structures.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{names}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}) – A list of names corresponding to each dataset.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
None

\end{description}\end{quote}

\end{fulllineitems}



\section{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{d}
\item\relax\sphinxstyleindexentry{datasets}\sphinxstyleindexpageref{datasets:\detokenize{module-datasets}}
\indexspace
\bigletter{t}
\item\relax\sphinxstyleindexentry{top}\sphinxstyleindexpageref{top:\detokenize{module-top}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}